{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2408decc-8fd7-4e27-8f89-6560d313681f",
   "metadata": {},
   "source": [
    "- I ignored stop-words because I would like to use the dynamic list approach from the Saif et al. paper.\n",
    "- The spellchecker is commented out because anything that didn't match its dictionary was replaced with None.\n",
    "- The translate library is supposed to handle over 100 languages, but did not work on my small sample\n",
    "- After running this, only 2 tweets were completely removed (and therefore replaced with 'cleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37ac2b6-8691-4b35-8930-2556a47f2499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting textsearch>=0.0.21 (from contractions)\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "     ---------------------------------------- 0.0/289.9 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/289.9 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 61.4/289.9 kB 812.7 kB/s eta 0:00:01\n",
      "     -------------------------------------  286.7/289.9 kB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 289.9/289.9 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
      "  Downloading pyahocorasick-2.0.0-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fbf092e-3d06-4485-9f14-15aa0ecfc568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Obtaining dependency information for emoji from https://files.pythonhosted.org/packages/96/c6/0114b2040a96561fd1b44c75df749bbd3c898bf8047fb5ce8d7590d2dee6/emoji-2.8.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading emoji-2.8.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
      "   ---------------------------------------- 0.0/358.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/358.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/358.9 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 41.0/358.9 kB 393.8 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 235.5/358.9 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 358.9/358.9 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8225c5e-7e8c-482b-9f88-cee5604b7764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n",
      "     ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.4 MB 187.9 kB/s eta 0:00:19\n",
      "      --------------------------------------- 0.1/3.4 MB 299.4 kB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.2/3.4 MB 706.2 kB/s eta 0:00:05\n",
      "     ------- -------------------------------- 0.6/3.4 MB 2.4 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 2.4/3.4 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.4/3.4 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.4/3.4 MB 9.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92d54ff1-3e02-450d-814e-62ffc06e2084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting translate\n",
      "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: click in c:\\users\\siobh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from translate) (8.1.7)\n",
      "Collecting lxml (from translate)\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/31/58/e3b3dd6bb2ab7404f1f4992e2d0e6926ed40cef8ce1b3bbefd95877499e1/lxml-4.9.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\siobh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from translate) (2.31.0)\n",
      "Collecting libretranslatepy==2.1.1 (from translate)\n",
      "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\siobh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->translate) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\siobh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->translate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siobh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->translate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\siobh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->translate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siobh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->translate) (2023.7.22)\n",
      "Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/3.8 MB 656.4 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.2/3.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.2/3.8 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.9/3.8 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 14.1 MB/s eta 0:00:00\n",
      "Installing collected packages: libretranslatepy, lxml, translate\n",
      "Successfully installed libretranslatepy-2.1.1 lxml-4.9.3 translate-3.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4a26cb-0f86-4d28-ab07-61c8bc25583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import contractions\n",
    "import emoji\n",
    "import html\n",
    "\n",
    "# from spellchecker import SpellChecker\n",
    "from translate import Translator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5353818-4c95-47ad-a8a4-f8781c30941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize spellchecker\n",
    "# spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb0303c-0b67-4923-aed9-e4f6867cb315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize translator\n",
    "translator= Translator(to_lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0d48c62-afe9-42c2-a5c2-881d38ecab87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_tweets.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25da2eb4-4b25-4c71-9938-0ec1ce0c61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_non_english(text):\n",
    "    for char in text:\n",
    "        # Check if the character is a letter and not in the ASCII range for English letters\n",
    "        if char.isalpha() and ord(char) > 127:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9aa1bd-d39e-4164-8790-679564741142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def spell_check(text):\n",
    "#     words = text.split()\n",
    "#     corrected_words = [spell.correction(word) for word in words]\n",
    "#     corrected_text = ' '.join(corrected_words)\n",
    "#     return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48770017-19a7-4014-8e47-3bde0a667230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # expand contractions\n",
    "    cleaned_text = contractions.fix(text)\n",
    "    # remove usernames\n",
    "    cleaned_text = cleaned_text.replace('@user', '')\n",
    "    # replace emojis with descriptive text\n",
    "    cleaned_text = emoji.demojize(cleaned_text)\n",
    "    # replace html characters with symbols\n",
    "    cleaned_text = html.unescape(cleaned_text)\n",
    "    # translate non-English languages\n",
    "    if has_non_english(cleaned_text) == True:\n",
    "        cleaned_text = translator.translate(cleaned_text) #doesn't work as intended on non-major languages\n",
    "    # remove special characters\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', cleaned_text)\n",
    "    # convert to all lowercase characters\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    if type(cleaned_text) == None:\n",
    "        cleaned_text = 'cleaned'\n",
    "    if cleaned_text.isspace():\n",
    "        cleaned_text = 'cleaned'\n",
    "    return cleaned_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27df1b9a-2c91-4fe5-baac-4cfca9e00447",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet'] = data['tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6afd0509-a375-432f-9c7d-ac7b496bd408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks for lyft credit i cannot use because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>model   i love you take with you all the time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0    when a father is dysfunctional and is so sel...\n",
       "1   2      0    thanks for lyft credit i cannot use because ...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  model   i love you take with you all the time ...\n",
       "4   5      0               factsguide society now    motivation"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d04fbbd-7eb5-4fb2-99a7-46f781f39da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('cleaned_data.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a85209b3-15d6-4f9b-9a40-910d63a3c6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of cells with 'cleaned': 2\n"
     ]
    }
   ],
   "source": [
    "# sum all the 'cleaned' cells\n",
    "sum_cleaned_cells = 0\n",
    "for row in data.values:\n",
    "    for cell in row:\n",
    "        if cell == 'cleaned':\n",
    "            sum_cleaned_cells += 1\n",
    "\n",
    "print(\"Sum of cells with 'cleaned':\", sum_cleaned_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba1ea9-7d4d-48ef-8c2d-ccfa2bf2ecb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
